{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b3c7b04-700f-4e09-9221-37369e20f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfc563fa-cb51-4837-9bb6-dd2e420d429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets_path=\"C:\\\\Users\\\\asus\\\\Desktop\\\\Data Science\\\\Machine Learning\\\\Project\\\\Datasets\"\n",
    "Data=pd.read_csv(f\"{Datasets_path}\\\\delays_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e93dcec-75d7-4b37-9cde-0f55a39d1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe8ad3bc-ca70-496e-9fc6-6c57b56abb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pd.get_dummies() for one-hot encoding\n",
    "Data = pd.get_dummies(Data, columns=['Arrival_State'], drop_first=True)\n",
    "Data = pd.get_dummies(Data, columns=['Departure_State'], drop_first=True)\n",
    "Data = pd.get_dummies(Data, columns=['Marketing_Airline'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32c7897-6dbd-4075-80c5-b8fad4be272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def handle_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "    # Impute upper outliers with upper limit\n",
    "    series = np.where(series > upper_limit, upper_limit, series)\n",
    "    # Impute lower outliers with lower limit\n",
    "    series = np.where(series < lower_limit, lower_limit, series)\n",
    "    return series\n",
    "\n",
    "numeric_features = Data.select_dtypes(include=[np.number]).columns\n",
    "Data[numeric_features] = Data[numeric_features].apply(handle_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e06ba3d7-c6cb-49da-bc7c-9a7e4ead471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numeric_columns = Data.select_dtypes(include=[np.number]).columns\n",
    "Q1 = Data[numeric_columns].quantile(0.25)\n",
    "Q3 = Data[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# Define the threshold for outliers\n",
    "threshold = 1.5\n",
    "# Filter out rows with outliers in any numeric column\n",
    "Data = Data[~((Data[numeric_columns] < (Q1 - threshold * IQR)) | (Data[numeric_columns] > (Q3 + threshold * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44602002-ce28-4535-af7a-7fd2ed2266fd",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d7676-0393-4f43-b704-d9c9c54954d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Assuming you have your dataset loaded into a DataFrame called 'data'\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = Data.drop(columns=['Arrival_Delay'])\n",
    "y = Data['Arrival_Delay']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the Lasso model\n",
    "lasso = Lasso(alpha=0.1)\n",
    "# Fit the Lasso model to the training data\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Select features with non-zero coefficients\n",
    "selected_features = SelectFromModel(lasso, prefit=True).get_support()\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X.columns[selected_features]\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b32a6d-6431-4219-962d-ae3bf71231d4",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6bb65e-40c5-497a-81a7-814472245baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "# Assuming Data is your DataFrame where Arrival_Delay is one of the features\n",
    "X = Data.drop(columns=['Arrival_Delay'])  # Features\n",
    "y = Data['Arrival_Delay']  # Target variable\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with GradientBoostingRegressor\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Making predictions using cross-validation\n",
    "y_pred_cv = cross_val_predict(best_model, X_scaled, y, cv=5)\n",
    "\n",
    "# Calculating MAPE\n",
    "mape = mean_absolute_percentage_error(y, y_pred_cv)\n",
    "\n",
    "# Calculating MAE\n",
    "mae = mean_absolute_error(y, y_pred_cv)\n",
    "\n",
    "# Calculating RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e9e773-3e7f-43ad-be2a-5c74b405f0af",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7cbc97-bb7f-4756-8704-006130875f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 17.075928632628965\n",
      "RMSE: 5.1914302499063565\n",
      "MAE: 4.027635404182541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming Data_no_outliers is your DataFrame where Arrival_Delay is one of the features\n",
    "X = Data.drop(columns=['Arrival_Delay'])  # Features\n",
    "y = Data['Arrival_Delay']  # Target variable\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Setting up parameter grid for GridSearchCV\n",
    "param_grid = {'n_estimators': [50, 100, 150], 'max_depth': [3, 4, 5]}\n",
    "\n",
    "# Initialize GridSearchCV with XGBRegressor\n",
    "grid_search = GridSearchCV(XGBRegressor(), param_grid, cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "                           scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Making predictions using cross-validation\n",
    "y_pred_cv = cross_val_predict(best_model, X_scaled, y, cv=5)\n",
    "\n",
    "# Calculating MAPE\n",
    "mape = mean_absolute_percentage_error(y, y_pred_cv)\n",
    "\n",
    "# Calculating RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "\n",
    "# Calculating MAE\n",
    "mae = mean_absolute_error(y, y_pred_cv)\n",
    "\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5194ee32-c1c1-4ab6-be75-236c4d702008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 4.016387786343856\n",
      "MSE: 30.79189026983233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming Data is your DataFrame where Arrival_Delay is one of the features\n",
    "X = Data.drop(columns=['Arrival_Delay'])  # Features\n",
    "y = Data['Arrival_Delay']  # Target variable\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting the XGB Regressor\n",
    "model = XGBRegressor()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating MAPE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Calculating MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"MSE:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

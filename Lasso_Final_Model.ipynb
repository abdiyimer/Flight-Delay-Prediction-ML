{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a2950b-e56d-4cf3-9241-f3c348351acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa0f902-6d9c-4d8f-9abb-9cd994ffc468",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets_path=\"C:\\\\Users\\\\asus\\\\Desktop\\\\Data Science\\\\Machine Learning\\\\Project\\\\Datasets\"\n",
    "Data=pd.read_csv(f\"{Datasets_path}\\\\delays_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "367dbc29-835f-474a-aaa6-6c8082d67e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday                           0\n",
       "Month_of_Year                     0\n",
       "Day_of_Month                      0\n",
       "Scheduled_Departure_Time          0\n",
       "Scheduled_Arrival_Time            0\n",
       "Marketing_Airline            163551\n",
       "Marketing_Airline_DOT_ID          0\n",
       "Flight_Number                     0\n",
       "Origin_Airport_ID                 0\n",
       "Destination_Airport_ID       163094\n",
       "Flight_Cancelled                  0\n",
       "Departure_State                   0\n",
       "Arrival_State                     0\n",
       "Departure_Delay              206461\n",
       "Arrival_Delay                211306\n",
       "Diverted_Airport_Landings         0\n",
       "Taxi_Out_Time                 49225\n",
       "Taxi_In_Time                  49867\n",
       "Flight_Diverted                   0\n",
       "Actual_Departure_Time         48326\n",
       "Flight_Duration              211490\n",
       "Flight_Distance              163190\n",
       "Origin_Temperature           163190\n",
       "Destination_Temperature      163190\n",
       "Origin_Wind_Speed            211490\n",
       "Destination_Wind_Speed       211490\n",
       "Origin_Precipitation              0\n",
       "Destination_Precipitation         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ca6df89-8e7a-43b3-a379-57c812b42d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(838241, 25)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855ea6cc-169d-47de-b3c3-f554648a021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dcf1779-d787-4aba-8f22-09518b949180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Weekday', 'Month_of_Year', 'Day_of_Month', 'Scheduled_Departure_Time',\n",
       "       'Scheduled_Arrival_Time', 'Marketing_Airline',\n",
       "       'Marketing_Airline_DOT_ID', 'Flight_Number', 'Origin_Airport_ID',\n",
       "       'Destination_Airport_ID', 'Flight_Cancelled', 'Departure_State',\n",
       "       'Arrival_State', 'Departure_Delay', 'Arrival_Delay',\n",
       "       'Diverted_Airport_Landings', 'Taxi_Out_Time', 'Taxi_In_Time',\n",
       "       'Flight_Diverted', 'Actual_Departure_Time', 'Flight_Duration',\n",
       "       'Flight_Distance', 'Origin_Temperature', 'Destination_Temperature',\n",
       "       'Origin_Wind_Speed', 'Destination_Wind_Speed', 'Origin_Precipitation',\n",
       "       'Destination_Precipitation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09e1fe02-b3d8-46c0-907b-8b778cebd99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday                        int64\n",
       "Month_of_Year                  int64\n",
       "Day_of_Month                   int64\n",
       "Scheduled_Departure_Time       int64\n",
       "Scheduled_Arrival_Time         int64\n",
       "Marketing_Airline_DOT_ID       int64\n",
       "Flight_Number                  int64\n",
       "Origin_Airport_ID              int64\n",
       "Destination_Airport_ID       float64\n",
       "Flight_Cancelled                bool\n",
       "Departure_Delay              float64\n",
       "Arrival_Delay                float64\n",
       "Diverted_Airport_Landings      int64\n",
       "Taxi_Out_Time                float64\n",
       "Taxi_In_Time                 float64\n",
       "Flight_Diverted                 bool\n",
       "Actual_Departure_Time        float64\n",
       "Flight_Duration              float64\n",
       "Flight_Distance              float64\n",
       "Origin_Temperature           float64\n",
       "Destination_Temperature      float64\n",
       "Origin_Wind_Speed            float64\n",
       "Destination_Wind_Speed       float64\n",
       "Origin_Precipitation         float64\n",
       "Destination_Precipitation    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91758214-e7b9-4ec4-afa4-ae74106402b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_drop = ['Arrival_State', 'Departure_State', 'Marketing_Airline']\n",
    "# Data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d0f4eab-4935-44c8-b22a-3b5b74f792b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.get_dummies(Data, columns=['Arrival_State'], drop_first=True)\n",
    "Data = pd.get_dummies(Data, columns=['Departure_State'], drop_first=True)\n",
    "Data = pd.get_dummies(Data, columns=['Marketing_Airline'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a4ca1-df16-4259-bcfe-be6f895313bc",
   "metadata": {},
   "source": [
    "### Grid Search for CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20600a57-8e47-4bea-b23f-27716814cd0a",
   "metadata": {},
   "source": [
    "### Outlier Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92041bc8-5cbb-4eae-8f24-faa8dc4a8c1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numeric_columns = Data.select_dtypes(include=[np.number]).columns\n",
    "Q1 = Data[numeric_columns].quantile(0.25)\n",
    "Q3 = Data[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# Define the threshold for outliers\n",
    "threshold = 1.5\n",
    "# Filter out rows with outliers in any numeric column\n",
    "Data_no_outliers = Data[~((Data[numeric_columns] < (Q1 - threshold * IQR)) | (Data[numeric_columns] > (Q3 + threshold * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5692222f-53c7-4d6c-9091-3c75891deeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.1}\n",
      "Best MSE (from cross-validation): 48.63137219554509\n",
      "Root Mean Squared Error (RMSE) on test set: 6.935155690634248\n",
      "Mean Absolute Error (MAE) on test set: 5.305965713450897\n",
      "Mean Absolute Percentage Error (MAPE) on test set: 5.266880767952744\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming Data_no_outliers is your preprocessed DataFrame\n",
    "# X contains features, y contains target variable\n",
    "X = Data_no_outliers.drop(columns=['Arrival_Delay'])\n",
    "y = Data_no_outliers['Arrival_Delay']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(Lasso(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "print(f'Best MSE (from cross-validation): {best_score}')\n",
    "\n",
    "# Fit the Lasso regression model with the best parameters\n",
    "best_lasso = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_lasso.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE, MAE, and MAPE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f'Root Mean Squared Error (RMSE) on test set: {rmse}')\n",
    "print(f'Mean Absolute Error (MAE) on test set: {mae}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) on test set: {mape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ab985-8276-439b-b875-db4ac4fe85d9",
   "metadata": {},
   "source": [
    "### Outlier Imputed With Winsorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "528dfc7c-2329-4cf2-b974-1051ebfac8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_20976\\3431522854.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-14.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_20976\\3431522854.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-314.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_20976\\3431522854.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-123.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_20976\\3431522854.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '19509.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_20976\\3431522854.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-3027.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_20976\\3431522854.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '7189.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numeric_columns = Data.select_dtypes(include=[np.number]).columns\n",
    "Q1 = Data[numeric_columns].quantile(0.25)\n",
    "Q3 = Data[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "threshold = 1.5\n",
    "lower_limit = Q1 - threshold * IQR\n",
    "upper_limit = Q3 + threshold * IQR\n",
    "Data_imputed = Data.copy()\n",
    "for column in numeric_columns:\n",
    "    lower_outliers_mask = Data_imputed[column] < lower_limit[column]\n",
    "    Data_imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
    "for column in numeric_columns:\n",
    "    upper_outliers_mask = Data_imputed[column] > upper_limit[column]\n",
    "    Data_imputed.loc[upper_outliers_mask, column] = upper_limit[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "639dcd32-edf2-43c5-9aa4-610dbec67386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.1}\n",
      "Best MSE (from cross-validation): 94.61102802416546\n",
      "Root Mean Squared Error (RMSE) on test set: 9.731371391099657\n",
      "Mean Absolute Error (MAE) on test set: 7.260942914101785\n",
      "Mean Absolute Percentage Error (MAPE) on test set: 7.8795392757185585\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming Data_no_outliers is your preprocessed DataFrame\n",
    "# X contains features, y contains target variable\n",
    "X = Data_imputed.drop(columns=['Arrival_Delay'])\n",
    "y = Data_imputed['Arrival_Delay']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(Lasso(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "print(f'Best MSE (from cross-validation): {best_score}')\n",
    "\n",
    "# Fit the Lasso regression model with the best parameters\n",
    "best_lasso = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_lasso.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE, MAE, and MAPE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f'Root Mean Squared Error (RMSE) on test set: {rmse}')\n",
    "print(f'Mean Absolute Error (MAE) on test set: {mae}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) on test set: {mape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43ff21-fa18-4088-841a-12e9a956bb84",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "***Model only with the Significant Features***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09ccfff1-df3a-4081-adb3-396992e7c3ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance (Coefficients):\n",
      "Weekday: 0.0\n",
      "Month_of_Year: 0.26745574715810017\n",
      "Day_of_Month: -0.0\n",
      "Scheduled_Departure_Time: 0.0\n",
      "Scheduled_Arrival_Time: 0.0\n",
      "Marketing_Airline_DOT_ID: -0.0\n",
      "Flight_Number: -0.12750878323398407\n",
      "Origin_Airport_ID: -0.0\n",
      "Destination_Airport_ID: 0.0\n",
      "Flight_Cancelled: 0.0\n",
      "Departure_Delay: 5.344322497859857\n",
      "Diverted_Airport_Landings: 0.0\n",
      "Taxi_Out_Time: 2.155429840647149\n",
      "Taxi_In_Time: 0.6074069192906147\n",
      "Flight_Diverted: 0.0\n",
      "Actual_Departure_Time: 0.061014972333126034\n",
      "Flight_Duration: 0.0\n",
      "Flight_Distance: -0.1918515514366262\n",
      "Origin_Temperature: -0.0\n",
      "Destination_Temperature: -0.0\n",
      "Origin_Wind_Speed: 0.0\n",
      "Destination_Wind_Speed: 0.0\n",
      "Origin_Precipitation: 0.0\n",
      "Destination_Precipitation: 0.0\n",
      "Arrival_State_AL: 0.0\n",
      "Arrival_State_AR: 0.0\n",
      "Arrival_State_AZ: 0.0\n",
      "Arrival_State_CA: -0.0\n",
      "Arrival_State_CO: 0.0\n",
      "Arrival_State_CT: 0.0\n",
      "Arrival_State_DE: 0.0\n",
      "Arrival_State_FL: 0.0\n",
      "Arrival_State_GA: 0.0\n",
      "Arrival_State_HI: 0.18330275687935038\n",
      "Arrival_State_IA: -0.0\n",
      "Arrival_State_ID: 0.0\n",
      "Arrival_State_IL: -0.2266349437928931\n",
      "Arrival_State_IN: -0.0\n",
      "Arrival_State_KS: 0.0\n",
      "Arrival_State_KY: -0.0\n",
      "Arrival_State_LA: 0.0\n",
      "Arrival_State_MA: -0.0\n",
      "Arrival_State_MD: -0.0\n",
      "Arrival_State_ME: -0.0\n",
      "Arrival_State_MI: -0.0\n",
      "Arrival_State_MN: 0.0\n",
      "Arrival_State_MO: -0.0\n",
      "Arrival_State_MS: 0.0\n",
      "Arrival_State_MT: 0.0\n",
      "Arrival_State_NC: -0.0\n",
      "Arrival_State_ND: 0.0\n",
      "Arrival_State_NE: 0.0\n",
      "Arrival_State_NH: -0.0\n",
      "Arrival_State_NJ: -0.0\n",
      "Arrival_State_NM: 0.0\n",
      "Arrival_State_NV: 0.0\n",
      "Arrival_State_NY: -0.0\n",
      "Arrival_State_OH: 0.0\n",
      "Arrival_State_OK: 0.0\n",
      "Arrival_State_OR: 0.0\n",
      "Arrival_State_PA: 0.0\n",
      "Arrival_State_PR: -0.0\n",
      "Arrival_State_RI: -0.0\n",
      "Arrival_State_SC: -0.0\n",
      "Arrival_State_SD: 0.0\n",
      "Arrival_State_TN: 0.0\n",
      "Arrival_State_TT: 0.0\n",
      "Arrival_State_TX: -0.0\n",
      "Arrival_State_UT: -0.0\n",
      "Arrival_State_VA: 0.0\n",
      "Arrival_State_VI: 0.0\n",
      "Arrival_State_VT: -0.0\n",
      "Arrival_State_WA: 0.0\n",
      "Arrival_State_WI: 0.0\n",
      "Arrival_State_WV: -0.0\n",
      "Arrival_State_WY: 0.0\n",
      "Departure_State_AL: 0.0\n",
      "Departure_State_AR: 0.0\n",
      "Departure_State_AZ: 0.0\n",
      "Departure_State_CA: 0.0\n",
      "Departure_State_CO: 0.0\n",
      "Departure_State_CT: 0.0\n",
      "Departure_State_DE: 0.0\n",
      "Departure_State_FL: 0.0\n",
      "Departure_State_GA: 0.05378235737314727\n",
      "Departure_State_HI: 0.1840817536833467\n",
      "Departure_State_IA: -0.0\n",
      "Departure_State_ID: 0.0\n",
      "Departure_State_IL: -0.0\n",
      "Departure_State_IN: -0.0\n",
      "Departure_State_KS: 0.0\n",
      "Departure_State_KY: -0.0\n",
      "Departure_State_LA: 0.0\n",
      "Departure_State_MA: -0.0\n",
      "Departure_State_MD: -0.0\n",
      "Departure_State_ME: -0.0\n",
      "Departure_State_MI: -0.0\n",
      "Departure_State_MN: -0.0\n",
      "Departure_State_MO: -0.0\n",
      "Departure_State_MS: -0.0\n",
      "Departure_State_MT: 0.0\n",
      "Departure_State_NC: -0.0\n",
      "Departure_State_ND: -0.0\n",
      "Departure_State_NE: 0.0\n",
      "Departure_State_NH: -0.0\n",
      "Departure_State_NJ: -0.0\n",
      "Departure_State_NM: 0.0\n",
      "Departure_State_NV: 0.0\n",
      "Departure_State_NY: -0.4736929698413265\n",
      "Departure_State_OH: -0.0\n",
      "Departure_State_OK: -0.0\n",
      "Departure_State_OR: 0.0\n",
      "Departure_State_PA: -0.0\n",
      "Departure_State_PR: -0.0\n",
      "Departure_State_RI: 0.0\n",
      "Departure_State_SC: 0.0\n",
      "Departure_State_SD: -0.0\n",
      "Departure_State_TN: 0.0\n",
      "Departure_State_TT: 0.0\n",
      "Departure_State_TX: 0.07307937654553279\n",
      "Departure_State_UT: -0.0\n",
      "Departure_State_VA: -0.0\n",
      "Departure_State_VI: 0.0\n",
      "Departure_State_VT: -0.0\n",
      "Departure_State_WA: 0.0\n",
      "Departure_State_WI: -0.0\n",
      "Departure_State_WV: -0.0\n",
      "Departure_State_WY: -0.0\n",
      "Marketing_Airline_AS: 0.5689900024054448\n",
      "Marketing_Airline_B6: 0.0\n",
      "Marketing_Airline_DL: -0.0\n",
      "Marketing_Airline_F9: 0.0\n",
      "Marketing_Airline_G4: 0.0\n",
      "Marketing_Airline_HA: 0.18425785001534398\n",
      "Marketing_Airline_NK: 0.0\n",
      "Marketing_Airline_UA: -0.32239042261067036\n",
      "Marketing_Airline_WN: 0.0\n",
      "\n",
      "MAPE: 7.447061495471639\n",
      "MSE: 88.13086981864991\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "# Assuming X contains your features including all features, and y contains your target variable (Arrival_Delay)\n",
    "X = Data_no_outliers.drop(columns=['Arrival_Delay'])  # Assuming 'Arrival_Delay' is your target variable\n",
    "y = Data_no_outliers['Arrival_Delay']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing: Normalizing all features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fitting the Elastic Net model\n",
    "elastic_net = ElasticNet(alpha=1.0, l1_ratio=0.5)  # You can adjust alpha and l1_ratio as needed\n",
    "elastic_net.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extracting coefficients to identify important features\n",
    "feature_importance = elastic_net.coef_\n",
    "\n",
    "# Printing feature importance (coefficients)\n",
    "print(\"Feature Importance (Coefficients):\")\n",
    "for i, feature in enumerate(X.columns):\n",
    "    print(f\"{feature}: {feature_importance[i]}\")\n",
    "\n",
    "# Making predictions\n",
    "y_pred = elastic_net.predict(X_test_scaled)\n",
    "\n",
    "# Calculating MAPE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Calculating MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\nMAPE:\", mape)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41bb5b4-592d-4da2-b22c-2e7560edbde0",
   "metadata": {},
   "source": [
    "# FINAL MODEL !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c4e35c3-7b2e-46a1-98ba-4944481456cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant features: Index(['Month_of_Year', 'Scheduled_Departure_Time', 'Flight_Number',\n",
      "       'Departure_Delay', 'Taxi_Out_Time', 'Taxi_In_Time', 'Flight_Duration',\n",
      "       'Flight_Distance', 'Arrival_State_AL', 'Arrival_State_AR',\n",
      "       'Arrival_State_AZ', 'Arrival_State_CA', 'Arrival_State_CO',\n",
      "       'Arrival_State_CT', 'Arrival_State_FL', 'Arrival_State_GA',\n",
      "       'Arrival_State_HI', 'Arrival_State_ID', 'Arrival_State_IL',\n",
      "       'Arrival_State_MA', 'Arrival_State_ME', 'Arrival_State_MI',\n",
      "       'Arrival_State_MO', 'Arrival_State_MT', 'Arrival_State_NC',\n",
      "       'Arrival_State_NJ', 'Arrival_State_NV', 'Arrival_State_NY',\n",
      "       'Arrival_State_OH', 'Arrival_State_OR', 'Arrival_State_PA',\n",
      "       'Arrival_State_PR', 'Arrival_State_RI', 'Arrival_State_SC',\n",
      "       'Arrival_State_TT', 'Arrival_State_TX', 'Arrival_State_UT',\n",
      "       'Arrival_State_VA', 'Arrival_State_VI', 'Arrival_State_VT',\n",
      "       'Arrival_State_WA', 'Departure_State_AL', 'Departure_State_AZ',\n",
      "       'Departure_State_CA', 'Departure_State_CO', 'Departure_State_CT',\n",
      "       'Departure_State_FL', 'Departure_State_GA', 'Departure_State_HI',\n",
      "       'Departure_State_ID', 'Departure_State_IL', 'Departure_State_IN',\n",
      "       'Departure_State_KS', 'Departure_State_KY', 'Departure_State_MA',\n",
      "       'Departure_State_MD', 'Departure_State_ME', 'Departure_State_MI',\n",
      "       'Departure_State_MN', 'Departure_State_MT', 'Departure_State_NC',\n",
      "       'Departure_State_NH', 'Departure_State_NJ', 'Departure_State_NM',\n",
      "       'Departure_State_NV', 'Departure_State_NY', 'Departure_State_OH',\n",
      "       'Departure_State_OR', 'Departure_State_PA', 'Departure_State_RI',\n",
      "       'Departure_State_SC', 'Departure_State_TN', 'Departure_State_TX',\n",
      "       'Departure_State_UT', 'Departure_State_VA', 'Departure_State_VT',\n",
      "       'Departure_State_WA', 'Departure_State_WI', 'Departure_State_WV',\n",
      "       'Marketing_Airline_AS', 'Marketing_Airline_DL', 'Marketing_Airline_UA'],\n",
      "      dtype='object')\n",
      "Best parameters after feature selection: {'alpha': 0.1}\n",
      "Best MSE (from cross-validation) after feature selection: 48.63375614471314\n",
      "Mean Absolute Percentage Error (MAPE) on test set using significant features: 5.266880674958684\n",
      "Root Mean Squared Error (RMSE) on test set using significant features: 6.935155608246705\n",
      "Mean Absolute Error (MAE) on test set using significant features: 5.305965659621408\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "\n",
    "# Assuming Data_no_outliers is your preprocessed DataFrame\n",
    "# X contains features, y contains target variable\n",
    "X = Data_no_outliers.drop(columns=['Arrival_Delay'])\n",
    "y = Data_no_outliers['Arrival_Delay']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "lasso_grid_search = GridSearchCV(Lasso(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit Lasso to perform feature selection\n",
    "lasso_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best Lasso model\n",
    "best_lasso = lasso_grid_search.best_estimator_\n",
    "\n",
    "# Get the indices of non-zero coefficients\n",
    "significant_indices = np.where(best_lasso.coef_ != 0)[0]\n",
    "\n",
    "# Get the names of the significant features\n",
    "significant_features = X.columns[significant_indices]\n",
    "print(f'Significant features: {significant_features}')\n",
    "\n",
    "# Select only the significant features from X_train_scaled and X_test_scaled\n",
    "X_train_scaled_significant = X_train_scaled[:, significant_indices]\n",
    "X_test_scaled_significant = X_test_scaled[:, significant_indices]\n",
    "\n",
    "# Define the parameter grid for Lasso after feature selection\n",
    "lasso_param_grid = {'alpha': [0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "\n",
    "# Set up the GridSearchCV for Lasso after feature selection\n",
    "lasso_grid_search_significant = GridSearchCV(Lasso(), lasso_param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit Lasso again using only significant features\n",
    "lasso_grid_search_significant.fit(X_train_scaled_significant, y_train)\n",
    "\n",
    "# Get the best parameters and best score for Lasso after feature selection\n",
    "best_params_significant = lasso_grid_search_significant.best_params_\n",
    "best_score_significant = -lasso_grid_search_significant.best_score_\n",
    "\n",
    "print(f'Best parameters after feature selection: {best_params_significant}')\n",
    "print(f'Best MSE (from cross-validation) after feature selection: {best_score_significant}')\n",
    "\n",
    "# Fit the Lasso regression model with the best parameters using only significant features\n",
    "best_lasso_significant = lasso_grid_search_significant.best_estimator_\n",
    "\n",
    "# Predict on the test set using only significant features\n",
    "y_pred_significant = best_lasso_significant.predict(X_test_scaled_significant)\n",
    "\n",
    "# Calculate MAPE for significant features\n",
    "mape_significant = mean_absolute_percentage_error(y_test, y_pred_significant)\n",
    "\n",
    "# Calculate RMSE for significant features\n",
    "rmse_significant = mean_squared_error(y_test, y_pred_significant, squared=False)\n",
    "\n",
    "# Calculate MAE for significant features\n",
    "mae_significant = mean_absolute_error(y_test, y_pred_significant)\n",
    "\n",
    "print(f'Mean Absolute Percentage Error (MAPE) on test set using significant features: {mape_significant}')\n",
    "print(f'Root Mean Squared Error (RMSE) on test set using significant features: {rmse_significant}')\n",
    "print(f'Mean Absolute Error (MAE) on test set using significant features: {mae_significant}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9c148-3537-41af-8b8a-85254bddfdfc",
   "metadata": {},
   "source": [
    "## Test  Data set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ffe2d3-daba-4a2f-91c8-089e7eb14c9a",
   "metadata": {},
   "source": [
    "### Prediction only for the Non-Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1fa1e8f4-fe41-4a6d-a59c-420c2abb6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets_path=\"C:\\\\Users\\\\asus\\\\Desktop\\\\Data Science\\\\Machine Learning\\\\Project\\\\Datasets\"\n",
    "Data_test=pd.read_csv(f\"{Datasets_path}\\\\delays_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6e3c65a9-637d-4395-b93d-b18cdc30e299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday                          0\n",
       "Month_of_Year                    0\n",
       "Day_of_Month                     0\n",
       "Scheduled_Departure_Time         0\n",
       "Scheduled_Arrival_Time           0\n",
       "Marketing_Airline            40364\n",
       "Marketing_Airline_DOT_ID         0\n",
       "Flight_Number                    0\n",
       "Origin_Airport_ID                0\n",
       "Destination_Airport_ID       40821\n",
       "Flight_Cancelled                 0\n",
       "Departure_State                  0\n",
       "Arrival_State                    0\n",
       "Departure_Delay              51789\n",
       "Diverted_Airport_Landings        0\n",
       "Taxi_Out_Time                12264\n",
       "Taxi_In_Time                 12430\n",
       "Flight_Diverted                  0\n",
       "Actual_Departure_Time        12016\n",
       "Flight_Duration              52666\n",
       "Flight_Distance              40725\n",
       "Origin_Temperature           40725\n",
       "Destination_Temperature      40725\n",
       "Origin_Wind_Speed            52666\n",
       "Destination_Wind_Speed       52666\n",
       "Origin_Precipitation             0\n",
       "Destination_Precipitation        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "68a092ee-2749-4efa-a07f-062b0f64ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2fdb733b-1d7e-40cd-a915-61bbe9a55b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test = pd.get_dummies(Data_test, columns=['Arrival_State'], drop_first=True)\n",
    "Data_test = pd.get_dummies(Data_test, columns=['Departure_State'], drop_first=True)\n",
    "Data_test = pd.get_dummies(Data_test, columns=['Marketing_Airline'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "52586eb7-81a2-438f-be50-f347b4ad12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# numeric_columns = Data_test.select_dtypes(include=[np.number]).columns\n",
    "# Q1 = Data_test[numeric_columns].quantile(0.25)\n",
    "# Q3 = Data_test[numeric_columns].quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# # Define the threshold for outliers\n",
    "# threshold = 1.5\n",
    "# # Filter out rows with outliers in any numeric column\n",
    "# Data_no_outliers = Data_test[~((Data_test[numeric_columns] < (Q1 - threshold * IQR)) | (Data_test[numeric_columns] > (Q3 + threshold * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575f5e68-78f3-48d1-82fa-dfd8c39dc8f6",
   "metadata": {},
   "source": [
    "### Outlier Handling\n",
    "***Winsorization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "059461a3-1176-4854-8d33-ad342c17a4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_16304\\1493213730.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-14.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_test_outlier_Imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_16304\\1493213730.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-119.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_test_outlier_Imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_16304\\1493213730.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '19509.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_test_outlier_Imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_16304\\1493213730.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-3040.25' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_test_outlier_Imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_16304\\1493213730.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '7189.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_test_outlier_Imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numeric_columns = Data_test.select_dtypes(include=[np.number]).columns\n",
    "Q1 = Data_test[numeric_columns].quantile(0.25)\n",
    "Q3 = Data_test[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "threshold = 1.5\n",
    "lower_limit = Q1 - threshold * IQR\n",
    "upper_limit = Q3 + threshold * IQR\n",
    "Data_test_outlier_Imputed = Data_test.copy()\n",
    "for column in numeric_columns:\n",
    "    lower_outliers_mask = Data_test_outlier_Imputed[column] < lower_limit[column]\n",
    "    Data_test_outlier_Imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
    "for column in numeric_columns:\n",
    "    upper_outliers_mask = Data_test_outlier_Imputed[column] > upper_limit[column]\n",
    "    Data_test_outlier_Imputed.loc[upper_outliers_mask, column] = upper_limit[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b1c693d-71c7-4a42-a01a-01e2b5e735cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday                     0\n",
       "Month_of_Year               0\n",
       "Day_of_Month                0\n",
       "Scheduled_Departure_Time    0\n",
       "Scheduled_Arrival_Time      0\n",
       "                           ..\n",
       "Marketing_Airline_G4        0\n",
       "Marketing_Airline_HA        0\n",
       "Marketing_Airline_NK        0\n",
       "Marketing_Airline_UA        0\n",
       "Marketing_Airline_WN        0\n",
       "Length: 137, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf3435-240f-40a7-a954-5467c31fec93",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "675a3730-89f3-4c9b-8bcf-dbbcc4284fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to: C:\\Users\\asus\\Desktop\\Data Science\\Machine Learning\\Project\\Datasets\\Prediction_for_Non_Missing_Observations.csv\n"
     ]
    }
   ],
   "source": [
    "# Assuming new_test_data is your new dataset without the target variable\n",
    "new_test_data_scaled = scaler.transform(Data_test_outlier_Imputed)\n",
    "\n",
    "# Select only the significant features\n",
    "new_test_data_scaled_significant = new_test_data_scaled[:, significant_indices]\n",
    "\n",
    "# Predict the target variable using the trained model with significant features\n",
    "predictions = best_lasso_significant.predict(new_test_data_scaled_significant)\n",
    "\n",
    "# Create a DataFrame to store predictions with their indices\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Index': Data_test_outlier_Imputed.index,\n",
    "    'Predicted_Arrival_Delay': predictions\n",
    "})\n",
    "\n",
    "# Save the predictions to a CSV file at the specified path\n",
    "predictions_file_path = os.path.join(Datasets_path, \"Prediction_for_Non_Missing_Observations.csv\")\n",
    "predictions_df.to_csv(predictions_file_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to: {predictions_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cbc10-664b-4fca-be27-6626c4d8bd02",
   "metadata": {},
   "source": [
    "### Prediction for the whole Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "570b67cc-d638-4864-9e5e-2d7cbb0730ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets_path=\"C:\\\\Users\\\\asus\\\\Desktop\\\\Data Science\\\\Machine Learning\\\\Project\\\\Datasets\"\n",
    "Data_test_whole=pd.read_csv(f\"{Datasets_path}\\\\delays_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d702243b-6b84-4d20-bfba-9efa18594a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday                          0\n",
       "Month_of_Year                    0\n",
       "Day_of_Month                     0\n",
       "Scheduled_Departure_Time         0\n",
       "Scheduled_Arrival_Time           0\n",
       "Marketing_Airline            40364\n",
       "Marketing_Airline_DOT_ID         0\n",
       "Flight_Number                    0\n",
       "Origin_Airport_ID                0\n",
       "Destination_Airport_ID       40821\n",
       "Flight_Cancelled                 0\n",
       "Departure_State                  0\n",
       "Arrival_State                    0\n",
       "Departure_Delay              51789\n",
       "Diverted_Airport_Landings        0\n",
       "Taxi_Out_Time                12264\n",
       "Taxi_In_Time                 12430\n",
       "Flight_Diverted                  0\n",
       "Actual_Departure_Time        12016\n",
       "Flight_Duration              52666\n",
       "Flight_Distance              40725\n",
       "Origin_Temperature           40725\n",
       "Destination_Temperature      40725\n",
       "Origin_Wind_Speed            52666\n",
       "Destination_Wind_Speed       52666\n",
       "Origin_Precipitation             0\n",
       "Destination_Precipitation        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_test_whole.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2ae7e-f1f6-4006-88a9-0bfc866a0a3e",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d5ddea79-6344-4444-9a1e-000c79c2850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test_whole['Marketing_Airline'] = Data_test_whole.groupby('Marketing_Airline_DOT_ID')['Marketing_Airline'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7dc64e81-5711-483c-ae67-2fc163bf32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Scheduled_Departure_Time' and fill missing values of 'Departure_Delay' with mean\n",
    "Data_test_whole['Departure_Delay'] = Data_test_whole.groupby('Scheduled_Departure_Time')['Departure_Delay'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8d9bcd56-4d6c-4f81-b4bf-60141c6d7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test_whole['Departure_Delay'].fillna(Data_test_whole['Departure_Delay'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "33268464-6523-4d1f-bd1f-2b300b694291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12430"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_test_whole.Taxi_In_Time.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9a47e6ba-72ce-4abc-9610-892fe5eca006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Scheduled_Departure_Time' and fill missing values of 'Departure_Delay' with mean\n",
    "Data_test_whole['Taxi_Out_Time'] = Data_test_whole.groupby('Origin_Airport_ID')['Taxi_Out_Time'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "07fa8d83-c9a9-438b-b73c-f96feea46bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test_whole['Taxi_Out_Time'].fillna(Data_test_whole['Taxi_Out_Time'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "75d451f9-7cd7-44ae-a6ed-9695c8e3f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Select relevant features\n",
    "relevant_features = ['Marketing_Airline_DOT_ID', 'Taxi_In_Time']\n",
    "\n",
    "# Group by 'Destination_Airport_ID' and impute missing values of 'Taxi_In_Time' by median within each group\n",
    "grouped = Data_test_whole.groupby(['Marketing_Airline_DOT_ID'])\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Impute missing values for 'Taxi_In_Time' within each group\n",
    "Data_test_whole['Taxi_In_Time'] = grouped['Taxi_In_Time'].transform(lambda x: imputer.fit_transform(x.values.reshape(-1, 1)).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2d1b3e6a-dbd9-45e3-882a-87b75114b4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday                     0\n",
       "Month_of_Year               0\n",
       "Day_of_Month                0\n",
       "Scheduled_Departure_Time    0\n",
       "Scheduled_Arrival_Time      0\n",
       "                           ..\n",
       "Marketing_Airline_G4        0\n",
       "Marketing_Airline_HA        0\n",
       "Marketing_Airline_NK        0\n",
       "Marketing_Airline_UA        0\n",
       "Marketing_Airline_WN        0\n",
       "Length: 137, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_test_whole.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "54afa8cc-4553-46f6-b416-4d786dadfd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Scheduled_Departure_Time' and fill missing values of 'Departure_Delay' with mean\n",
    "Data_test_whole['Flight_Duration'] = Data_test_whole.groupby('Origin_Airport_ID')['Flight_Duration'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f269f2a1-de35-4d09-9e13-68f9de7bc5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test_whole['Flight_Duration'].fillna(Data_test_whole['Flight_Duration'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d208d6e4-09e3-4d82-9239-01b4d2d6f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test_whole['Flight_Distance'] = Data_test_whole.groupby('Origin_Airport_ID')['Flight_Distance'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "96bcc692-3e86-48ad-bd10-2cbea480f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_test_whole = pd.get_dummies(Data_test_whole, columns=['Arrival_State'], drop_first=True)\n",
    "Data_test_whole = pd.get_dummies(Data_test_whole, columns=['Departure_State'], drop_first=True)\n",
    "Data_test_whole = pd.get_dummies(Data_test_whole, columns=['Marketing_Airline'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd572a-b684-4d0a-80da-67acb3d5eb37",
   "metadata": {},
   "source": [
    "### Handling Outliers\n",
    "***Imputing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "43352ed1-09a5-454a-87e5-88103e53e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# numeric_columns = Data.select_dtypes(include=[np.number]).columns\n",
    "# Q1 = Data[numeric_columns].quantile(0.25)\n",
    "# Q3 = Data[numeric_columns].quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# # Define the threshold for outliers\n",
    "# threshold = 1.5\n",
    "# # Filter out rows with outliers in any numeric column\n",
    "# Data = Data[~((Data[numeric_columns] < (Q1 - threshold * IQR)) | (Data[numeric_columns] > (Q3 + threshold * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e8246074-8d9a-47b2-948f-2a6bbed55b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_16304\\3721539595.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-3067.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  Data_test_outlier_Imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numeric_columns = Data_test_whole_Sig.select_dtypes(include=[np.number]).columns\n",
    "Q1 = Data_test_whole_Sig[numeric_columns].quantile(0.25)\n",
    "Q3 = Data_test_whole_Sig[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "threshold = 1.5\n",
    "lower_limit = Q1 - threshold * IQR\n",
    "upper_limit = Q3 + threshold * IQR\n",
    "Data_test_outlier_Imputed = Data_test_whole.copy()\n",
    "for column in numeric_columns:\n",
    "    lower_outliers_mask = Data_test_outlier_Imputed[column] < lower_limit[column]\n",
    "    Data_test_outlier_Imputed.loc[lower_outliers_mask, column] = lower_limit[column]\n",
    "for column in numeric_columns:\n",
    "    upper_outliers_mask = abdi[column] > upper_limit[column]\n",
    "    Data_test_outlier_Imputed.loc[upper_outliers_mask, column] = upper_limit[column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edad3e9-de1c-4b17-9084-6c88ebe5a3f6",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "98139bae-f3c0-42ec-8c95-187f5851f0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to: C:\\Users\\asus\\Desktop\\Data Science\\Machine Learning\\Project\\Datasets\\Predictions_for_all_test_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Scale the test data using the same scaler fitted on the entire training dataset\n",
    "Data_test_imputed_scaled = scaler.transform(Data_test_outlier_Imputed)\n",
    "\n",
    "# Select only the significant features from the scaled test data\n",
    "new_test_data_scaled_significant = Data_test_imputed_scaled[:, significant_indices]\n",
    "\n",
    "# Predict the target variable using the model fitted with only significant features\n",
    "predictions = best_lasso_significant.predict(new_test_data_scaled_significant)\n",
    "\n",
    "# Create a DataFrame to store predictions with their indices\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Index': Data_test_outlier_Imputed.index,  # Assuming the index is preserved\n",
    "    'Predicted_Arrival_Delay': predictions\n",
    "})\n",
    "\n",
    "# Save the predictions to a CSV file at the specified path\n",
    "predictions_file_path = os.path.join(Datasets_path, \"Predictions_for_all_test_data.cs\")\n",
    "predictions_df.to_csv(predictions_file_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to: {predictions_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99feb4c7-f1f4-4ac1-8869-7e802f7179e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3491af6-e9ce-46f8-a791-dd123eba3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets_path=\"C:\\\\Users\\\\asus\\\\Desktop\\\\Data Science\\\\Machine Learning\\\\Project\\\\Datasets\"\n",
    "Data=pd.read_csv(f\"{Datasets_path}\\\\delays_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a06dc34-caa0-4d8a-976c-58770926a72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Weekday', 'Month_of_Year', 'Day_of_Month', 'Scheduled_Departure_Time',\n",
       "       'Scheduled_Arrival_Time', 'Marketing_Airline_DOT_ID', 'Flight_Number',\n",
       "       'Origin_Airport_ID', 'Destination_Airport_ID', 'Flight_Cancelled',\n",
       "       ...\n",
       "       'Departure_State_WY', 'Marketing_Airline_AS', 'Marketing_Airline_B6',\n",
       "       'Marketing_Airline_DL', 'Marketing_Airline_F9', 'Marketing_Airline_G4',\n",
       "       'Marketing_Airline_HA', 'Marketing_Airline_NK', 'Marketing_Airline_UA',\n",
       "       'Marketing_Airline_WN'],\n",
       "      dtype='object', length=138)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bef011-c6fb-4d72-a0ba-fe35414c7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96e5506d-ca72-4e28-b74c-d6ba2867444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pd.get_dummies() for one-hot encoding\n",
    "Data = pd.get_dummies(Data, columns=['Arrival_State'], drop_first=True)\n",
    "Data = pd.get_dummies(Data, columns=['Departure_State'], drop_first=True)\n",
    "Data = pd.get_dummies(Data, columns=['Marketing_Airline'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d66c263-2874-4ad6-87c5-d5992ced70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the columns to drop\n",
    "# columns_to_drop = ['Arrival_State', 'Departure_State', 'Marketing_Airline']\n",
    "# Data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ac641-9506-4aa3-a94f-e6a7c6c9041d",
   "metadata": {},
   "source": [
    "### Outlier Handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cbe396e-5475-497e-962c-bbb208b5a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def handle_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "    # Impute upper outliers with upper limit\n",
    "    series = np.where(series > upper_limit, upper_limit, series)\n",
    "    # Impute lower outliers with lower limit\n",
    "    series = np.where(series < lower_limit, lower_limit, series)\n",
    "    return series\n",
    "\n",
    "numeric_features = Data.select_dtypes(include=[np.number]).columns\n",
    "Data[numeric_features] = Data[numeric_features].apply(handle_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6437af-ec05-411f-91f6-167a672e5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# numeric_columns = Data.select_dtypes(include=[np.number]).columns\n",
    "# Q1 = Data[numeric_columns].quantile(0.25)\n",
    "# Q3 = Data[numeric_columns].quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# # Define the threshold for outliers\n",
    "# threshold = 1.5\n",
    "# # Filter out rows with outliers in any numeric column\n",
    "# Data = Data[~((Data[numeric_columns] < (Q1 - threshold * IQR)) | (Data[numeric_columns] > (Q3 + threshold * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adfdf15-1a77-43e6-86a2-e3f187ec3793",
   "metadata": {},
   "source": [
    "### Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c32af8e2-4dbc-4523-a1a9-b30cb25d3fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Index(['Month_of_Year', 'Scheduled_Departure_Time', 'Flight_Number',\n",
      "       'Departure_Delay', 'Taxi_Out_Time', 'Taxi_In_Time',\n",
      "       'Actual_Departure_Time', 'Flight_Duration', 'Flight_Distance',\n",
      "       'Arrival_State_AL', 'Arrival_State_AZ', 'Arrival_State_CA',\n",
      "       'Arrival_State_CO', 'Arrival_State_CT', 'Arrival_State_FL',\n",
      "       'Arrival_State_HI', 'Arrival_State_IL', 'Arrival_State_MD',\n",
      "       'Arrival_State_ME', 'Arrival_State_NC', 'Arrival_State_NE',\n",
      "       'Arrival_State_NV', 'Arrival_State_OH', 'Arrival_State_PA',\n",
      "       'Arrival_State_PR', 'Arrival_State_RI', 'Arrival_State_SC',\n",
      "       'Arrival_State_TX', 'Arrival_State_UT', 'Arrival_State_VA',\n",
      "       'Arrival_State_VI', 'Arrival_State_VT', 'Arrival_State_WA',\n",
      "       'Departure_State_AZ', 'Departure_State_CA', 'Departure_State_CO',\n",
      "       'Departure_State_FL', 'Departure_State_HI', 'Departure_State_ID',\n",
      "       'Departure_State_IL', 'Departure_State_KS', 'Departure_State_KY',\n",
      "       'Departure_State_LA', 'Departure_State_MA', 'Departure_State_MD',\n",
      "       'Departure_State_ME', 'Departure_State_MI', 'Departure_State_MO',\n",
      "       'Departure_State_NC', 'Departure_State_NJ', 'Departure_State_NM',\n",
      "       'Departure_State_NV', 'Departure_State_NY', 'Departure_State_OH',\n",
      "       'Departure_State_OR', 'Departure_State_PA', 'Departure_State_RI',\n",
      "       'Departure_State_TN', 'Departure_State_TT', 'Departure_State_TX',\n",
      "       'Departure_State_UT', 'Departure_State_VA', 'Departure_State_VT',\n",
      "       'Marketing_Airline_AS', 'Marketing_Airline_B6', 'Marketing_Airline_G4',\n",
      "       'Marketing_Airline_HA', 'Marketing_Airline_NK', 'Marketing_Airline_UA',\n",
      "       'Marketing_Airline_WN'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Assuming you have your dataset loaded into a DataFrame called 'data'\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = Data.drop(columns=['Arrival_Delay'])\n",
    "y = Data['Arrival_Delay']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the Lasso model\n",
    "lasso = Lasso(alpha=0.1)\n",
    "# Fit the Lasso model to the training data\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Select features with non-zero coefficients\n",
    "selected_features = SelectFromModel(lasso, prefit=True).get_support()\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X.columns[selected_features]\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8e8885-7c78-4ec7-b6d5-97143c5c36b4",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f4917-75ae-45c9-af2d-a96d88f9e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming Data is your DataFrame where Arrival_Delay is one of the features\n",
    "X = Data.drop(columns=['Arrival_Delay'])  # Features\n",
    "y = Data['Arrival_Delay']  # Target variable\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define the SVR model\n",
    "svr = SVR()\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Use only the significant features\n",
    "# Replace X_scaled with the actual variable name of your scaled features\n",
    "X_significant = X_scaled[:, significant_features_indices]\n",
    "\n",
    "# Fit the SVR model using cross-validation only on the significant features\n",
    "y_pred_cv = cross_val_predict(grid_search.best_estimator_, X_significant, y, cv=5)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mape = mean_absolute_percentage_error(y, y_pred_cv)\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "mae = mean_absolute_error(y, y_pred_cv)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee02aeae-6b4f-494f-a161-ade87989da3d",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25a989-056a-4810-a8ce-74de24596661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from math import sqrt  # Import sqrt function to calculate square root\n",
    "\n",
    "# Assuming Data_no_outliers is your preprocessed DataFrame\n",
    "# X contains features, y contains target variable\n",
    "X = Data.drop(columns=['Arrival_Delay'])\n",
    "y = Data['Arrival_Delay']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "print(f'Best MSE (from cross-validation): {best_score}')\n",
    "\n",
    "# Fit the KNN regression model with the best parameters\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)  # Calculate RMSE using square root of MSE\n",
    "\n",
    "print(f'Mean Absolute Error (MAE) on test set: {mae}')\n",
    "print(f'Mean Absolute Percentage Error (MAPE) on test set: {mape}')\n",
    "print(f'Root Mean Squared Error (RMSE) on test set: {rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
